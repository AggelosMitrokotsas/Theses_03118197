{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6483,"status":"ok","timestamp":1708506189653,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"zwT9bit74BmZ"},"outputs":[],"source":["\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from datetime import date\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from lxml import etree\n","import matplotlib.dates as mdates\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.cluster import KMeans\n","from sklearn.ensemble import GradientBoostingRegressor\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, median_absolute_error, explained_variance_score\n","from sklearn.metrics import mean_absolute_error, r2_score\n","from sklearn.model_selection import RandomizedSearchCV, train_test_split\n","from matplotlib.dates import AutoDateLocator, AutoDateFormatter\n","from scipy.stats import randint\n","from sklearn.tree import export_graphviz\n","from IPython.display import Image\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow import keras\n","from keras.preprocessing.sequence import TimeseriesGenerator\n","from keras import layers, models, optimizers, losses, metrics\n","from keras.models import Sequential\n","from keras.layers import Dense, SimpleRNN, LSTM\n","import graphviz\n","from IPython.display import Image\n","from keras.utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.optimizers import Adam\n","from keras.metrics import MeanSquaredError, MeanAbsoluteError\n","import psutil"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["houses = {}\n","house_names = []\n","for i in range(1, 22):\n","    # number 14 is missing from the dataset\n","    if i == 14:\n","        continue\n","    file_name = f'CLEAN_House{i}.csv'\n","    try:\n","        # path_to_Houses.csv\n","        df = pd.read_csv(file_name, parse_dates=['Time'])\n","        # Add the dataframe to the list\n","        houses[file_name] = df\n","        #houses.append(df)\n","        house_names.append(file_name)\n","        print(file_name)\n","        print(houses[file_name].head())\n","    except FileNotFoundError:\n","        print(f'File not found: {file_name}')\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":22685,"status":"ok","timestamp":1708506237418,"user":{"displayName":"Aggelos Mitrokotsas","userId":"16042582480483077405"},"user_tz":-120},"id":"J6FllXcqVfT2","outputId":"49997927-0a43-428f-8694-472894ed313c"},"outputs":[],"source":["for name, df in houses.items():\n","    null_values = df.isnull().sum()\n","    print(null_values)\n","    print(name)\n","\n","    #replace null values with the mean of their neighboring cells\n","    df['Aggregate'] = df['Aggregate'].fillna((df['Aggregate'].ffill() + df['Aggregate'].bfill()) / 2)\n","\n","    df['Aggregate'].fillna(method='bfill', inplace=True)\n","    df['Aggregate'].fillna(method='ffill', inplace=True)\n","\n","\n","    df['Time'] = pd.to_datetime(df['Time'])\n","    df.set_index('Time', inplace=True)\n","\n","\n","    #total energy consumption\n","    df['Aggregate'].plot(figsize=(20, 10))\n","    plt.title('Total Energy Consumption Over Time')\n","    plt.ylabel('Energy (kWh)')\n","    plt.xlabel('Time')\n","\n","    # Formatting date on x-axis\n","    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n","    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m')) \n","    plt.xticks(rotation = 90) \n","    \n","    plt.legend()\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.savefig(f'{name}.jpeg', format='jpeg', dpi=300)\n","\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"WNP5Hr0R6x-P","outputId":"67b6d7f9-932c-41e7-a436-309c539c7ab5"},"outputs":[],"source":["for name, df in houses.items():\n","    print(name)\n","    X = df.drop(['Aggregate', 'Time'], axis=1)\n","    y = df['Aggregate']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","    regressor = RandomForestRegressor(n_estimators=20, random_state=42)\n","    regressor.fit(X_train, y_train)\n","\n","    #predict on test set\n","    predictions = regressor.predict(X_test)\n","\n","    #Evaluation\n","    rmse = mean_squared_error(y_test, predictions, squared=False)\n","    print(f'Root Mean Squared Error: {rmse}')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aIgq3Sdsphy1","outputId":"8d21eb9e-459c-4784-921c-7aa01226405e"},"outputs":[],"source":["for name, df in houses.items():\n","    print(name)\n","    X = df.drop(['Aggregate', 'Time'], axis=1)\n","    y = df['Aggregate']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","    predictions = model.predict(X_test)\n","\n","    print('RMSE:', mean_squared_error(y_test, predictions, squared=False))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"4REWAUgUf2wI","outputId":"73aa848f-aa2a-4033-c7dc-57151977913d"},"outputs":[],"source":["for name, df in houses.items():\n","    print(name)\n","    model = GradientBoostingRegressor(n_estimators=20, random_state=42)\n","    model.fit(X_train, y_train)\n","    predictions = model.predict(X_test)\n","\n","    print('RMSE:', mean_squared_error(y_test, predictions, squared=False))\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# Adapting the concepts of accuracy, precision, recall and confusion matrix by defining thresholds within which predictions are considered \"accurate\" or \"correct.\" \n","# This process is sometimes referred to as \"binning\" or \"categorizing\" continuous data to fit a classification model framework. \n","def dynamic_regression_accuracy(y_true, y_pred, scale_factor=0.1):\n","    \"\"\"Calculate accuracy with a dynamic tolerance based on a scale factor times the standard deviation of y_true.\"\"\"\n","    tolerance = scale_factor * np.std(y_true)\n","    correct = np.abs(y_true - y_pred) <= tolerance\n","    return np.mean(correct)\n","\n","\n","def binarize_data(y, threshold):\n","    \"\"\"Convert continuous data into binary classes based on a threshold.\"\"\"\n","    return np.where(y > threshold, 1, 0)  # 1 for high consumption, 0 for low consumption\n","\n","def calculate_precision_recall(y_true, y_pred, threshold):\n","    \"\"\"Calculate precision for binarized data.\"\"\"\n","    y_true_binarized = binarize_data(y_true, threshold)\n","    y_pred_binarized = binarize_data(y_pred, threshold)\n","    \n","    precision = precision_score(y_true_binarized, y_pred_binarized)\n","\n","    \n","    return precision\n","\n","def calculate_recall(y_true, y_pred, threshold):\n","    \"\"\"Calculate recall for binarized data.\"\"\"\n","    y_true_binarized = binarize_data(y_true, threshold)\n","    y_pred_binarized = binarize_data(y_pred, threshold)\n","    recall = recall_score(y_true_binarized, y_pred_binarized)\n","    return recall\n","\n","def create_confusion_matrix(y_true, y_pred, threshold):\n","    \"\"\"Create a confusion matrix for a given threshold for binarizing continuous outcomes.\"\"\"\n","    bins = [0, threshold, np.inf]\n","    y_true_binned = np.digitize(y_true, bins) - 1  # Convert to 0 or 1\n","    y_pred_binned = np.digitize(y_pred, bins) - 1\n","    cm = confusion_matrix(y_true_binned, y_pred_binned)\n","    return cm\n","\n","def custom_mape(y_true, y_pred):\n","    epsilon = 1e-8\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0, float('inf'))  # Clip predictions at zero\n","    \n","    mape = tf.reduce_mean(tf.abs((y_true - y_pred) / (tf.maximum(tf.abs(y_true), epsilon)))) * 100\n","    return mape\n","\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, SimpleRNN, LSTM, Bidirectional, GRU, Conv1D, MaxPooling1D, Flatten, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, TimeDistributed, Conv2D, Concatenate, Attention\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dropout, Dense, Input, GlobalAveragePooling1D, Add, Conv1D, MaxPooling1D, Bidirectional, LSTM, Attention, GRU, LeakyReLU, BatchNormalization \n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","import optuna\n","from optuna.integration import TFKerasPruningCallback\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error, explained_variance_score, mean_squared_log_error\n","from optuna.visualization import plot_optimization_history\n","from optuna.visualization import plot_param_importances\n","from optuna.visualization import plot_contour\n","from optuna.visualization import plot_parallel_coordinate\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dropout, Dense, Input, GlobalAveragePooling1D, Add, Conv1D, MaxPooling1D, Bidirectional, GRU, LeakyReLU\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from sklearn.preprocessing import RobustScaler\n","\n","\n","# Define RNN model\n","def create_rnn_model(input_shape, optimizer='adam', activation = 'relu', learning_rate=0.001):\n","    inputs = Input(shape=input_shape)\n","    x = SimpleRNN(32, activation=activation, return_sequences=True)(inputs)\n","    x = Dropout(0.3)(x)\n","    x = SimpleRNN(16, activation=activation, return_sequences=False)(x)\n","    x = Dropout(0.3)(x)\n","    outputs = Dense(1)(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=optimizer, loss=tf.losses.Huber(delta=0.5), metrics=['mse', 'mae'])\n","    return model\n","\n","# Define LSTM model\n","def create_lstm_model(input_shape, optimizer='adam', activation = 'relu', learning_rate=0.001):\n","    inputs = Input(shape=input_shape)\n","    x = LSTM(32, activation=activation, return_sequences=True)(inputs)\n","    x = Dropout(0.1)(x)\n","    x = LSTM(16, activation=activation)(inputs)\n","    x = Dropout(0.1)(x)\n","    outputs = Dense(1)(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=optimizer, loss=tf.losses.Huber(delta=0.5), metrics=['mse', 'mae'])\n","    return model\n","\n","# Define BiLSTM model\n","def create_bilstm_model(input_shape, optimizer='adam', activation = 'relu', learning_rate=0.001):\n","    inputs = Input(shape=input_shape)\n","    x = Bidirectional(LSTM(32, activation=activation))(inputs)\n","    outputs = Dense(1)(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=optimizer, loss=tf.losses.Huber(delta=0.5), metrics=['mse', 'mae'])\n","    return model\n","\n","# Define GRU model\n","def create_gru_model(input_shape, optimizer='adam', activation = 'relu', learning_rate=0.001):\n","    inputs = Input(shape=input_shape)\n","    x = GRU(32, activation=activation, return_sequences=True)(inputs)\n","    x = Dropout(0.1)(x)\n","    x = GRU(16, activation=activation)(inputs)\n","    x = Dropout(0.1)(x)\n","    outputs = Dense(1)(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=optimizer, loss=tf.losses.Huber(delta=0.5), metrics=['mse', 'mae'])\n","    return model\n","\n","# Define BiGRU model\n","def create_bigru_model(input_shape, optimizer='adam', activation = 'relu', learning_rate=0.001):\n","    inputs = Input(shape=input_shape)\n","    x = Bidirectional(GRU(32, activation=activation))(inputs)\n","    outputs = Dense(1)(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer=optimizer, loss=tf.losses.Huber(delta=0.5), metrics=['mse', 'mae'])\n","    return model\n","\n","\n","# Transformer Encoder Block\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1):\n","    # Multi-Head Self-Attention\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n","    x = Dropout(dropout)(x)\n","    x = Add()([x, inputs])  # Residual connection\n","    x = LayerNormalization(epsilon=1e-6)(x)\n","\n","    # Feed Forward Network\n","    x_ff = Dense(ff_dim, activation=LeakyReLU())(x)\n","    x_ff = Dropout(dropout)(x_ff)\n","    x_ff = Dense(inputs.shape[-1])(x_ff)\n","    x = Add()([x, x_ff])  # Residual connection\n","    x = LayerNormalization(epsilon=1e-6)(x)\n","\n","    return x\n","\n","\n","# Model Definition\n","def cnn_lstm_attention_transformer_model(input_shape, num_cnn_filters=16, kernel_size=2, lstm_units=32, gru_units=32, head_size=16, num_heads=2, ff_dim=16, num_transformer_blocks=3, dropout=0.2, weight_decay=1e-6):\n","    inputs = Input(shape=input_shape)\n","    \n","    x = Conv1D(filters=num_cnn_filters, kernel_size=kernel_size, padding='same', activation='relu', kernel_regularizer=l2(weight_decay))(inputs)\n","    x = MaxPooling1D(pool_size=2)(x) \n","    x = Conv1D(filters=num_cnn_filters, kernel_size=kernel_size, padding='same', activation='relu', kernel_regularizer=l2(weight_decay))(inputs)\n","    x = MaxPooling1D(pool_size=2)(x)\n","    x = Conv1D(filters=num_cnn_filters * 2, kernel_size=kernel_size, padding='same', activation='relu', kernel_regularizer=l2(weight_decay))(x)\n","    x = MaxPooling1D(pool_size=2)(x)\n","    x = Dropout(dropout)(x)  # Dropout after pooling\n","    \n","    x = LayerNormalization()(x)\n","\n","    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = Bidirectional(LSTM(lstm_units // 2, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = LayerNormalization()(x)\n","\n","    x = Bidirectional(GRU(gru_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = Bidirectional(GRU(gru_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = Bidirectional(GRU(gru_units // 2, return_sequences=True, dropout=dropout, recurrent_dropout=dropout, kernel_regularizer=l2(weight_decay)))(x)\n","    x = LeakyReLU()(x)\n","    x = LayerNormalization()(x)\n","\n","    # Attention Mechanism (optional)\n","    attention = Attention()([x, x])  # Self-attention over the LSTM/GRU output\n","    x = Add()([x, attention])  # Add residual connection after attention\n","    \n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)\n","\n","    x = GlobalAveragePooling1D()(x)\n","    x = Dropout(dropout)(x)  # Dropout after pooling layer\n","    outputs = Dense(1, kernel_regularizer=l2(weight_decay))(x)\n","    \n","    model = Model(inputs, outputs)\n","    model.compile(optimizer='adam', loss= tf.losses.Huber(delta=1.5), metrics=['mse', 'mae'])\n","    \n","    return model\n","\n","def create_features(df):\n","    df['Hour'] = df.index.hour\n","    df['Day_of_Week'] = df.index.dayofweek\n","    df['Month'] = df.index.month\n","    df['Lag_1'] = df['Aggregate'].shift(1)\n","    df['Lag_450'] = df['Aggregate'].shift(450)\n","    df['Lag_5400'] = df['Aggregate'].shift(5400)\n","    df['Lag_10800'] = df['Aggregate'].shift(10800)\n","    df.dropna(inplace=True)\n","    return df\n","\n","def print_cpu_usage(phase):\n","    cpu_percent = psutil.cpu_percent(interval=1)\n","    print(f\"CPU usage during {phase}: {cpu_percent}%\")\n","    \n","\n","def create_sequences_with_additional_features(dataset, additional_features, window_size=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset) - window_size):\n","        seq_X = dataset[i:(i + window_size), :]\n","        seq_features = additional_features[i + window_size - 1]  # Add the corresponding additional feature to each sequence\n","        dataX.append(np.concatenate((seq_X, np.tile(seq_features, (window_size, 1))), axis=1))\n","        dataY.append(dataset[i + window_size, :])\n","    return np.array(dataX), np.array(dataY)\n","\n","def prepare_timeseries_generator(data, features, window_size=24, batch_size=64):\n","    generator_input = np.concatenate([features, data], axis=1)  # Combine features and target for input\n","    generator = TimeseriesGenerator(generator_input, data, length=window_size, batch_size=batch_size)\n","    return generator\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["RNN_models={}\n","tf.get_logger().setLevel('ERROR')\n","for name, df in houses.items():\n","    print(name)\n","    \n","    df = create_features(df)\n","    \n","    # Step 1: Proper Scaling\n","    aggregate = df['Aggregate'].values.reshape(-1, 1)\n","    additional_features = df[['Hour', 'Day_of_Week', 'Month', 'Lag_1', 'Lag_450', 'Lag_5400', 'Lag_10800']].values\n","\n","    # Scale after splitting to avoid leakage\n","    split_point = int(len(aggregate) * 0.80)\n","    \n","    scaler_aggregate = RobustScaler()\n","    train_aggregate = scaler_aggregate.fit_transform(aggregate[:split_point])\n","    test_aggregate = scaler_aggregate.transform(aggregate[split_point:])\n","\n","    scaler_additional = RobustScaler()\n","    train_additional_features = scaler_additional.fit_transform(additional_features[:split_point])\n","    test_additional_features = scaler_additional.transform(additional_features[split_point:])\n","\n","    # Step 5: Investigate Overfitting (Balanced Split)\n","    window_size = 24\n","    batch_size = 64\n","    train_generator = prepare_timeseries_generator(train_aggregate, train_additional_features, window_size=window_size, batch_size=batch_size)\n","    test_generator = prepare_timeseries_generator(test_aggregate, test_additional_features, window_size=window_size, batch_size=batch_size)\n","\n","    input_shape = (window_size, train_generator[0][0].shape[2])\n","\n","    model = create_rnn_model(input_shape=input_shape)\n","\n","    early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-3)\n","    print_cpu_usage(\"Initialization\")\n","    history = model.fit(train_generator, epochs=30, validation_data=test_generator, callbacks=[early_stopping, reduce_lr], batch_size=batch_size)\n","    print_cpu_usage(\"after training\")\n","    \n","    print_cpu_usage(\"before prediction\")\n","    predictions = model.predict(test_generator)\n","    actual = test_aggregate[window_size:]  #Align actuals &  predictions\n","\n","    actual = scaler_aggregate.inverse_transform(actual)\n","    predictions = scaler_aggregate.inverse_transform(predictions)\n","    print_cpu_usage(\"after prediction\")\n","\n","    #  metrics\n","    rmse = mean_squared_error(actual, predictions, squared = False)\n","    mae = mean_absolute_error(actual, predictions)\n","    r2 = r2_score(actual, predictions)\n","    mse = mean_squared_error(actual, predictions)\n","    \n","    # Extra classification metrics for curiosity \n","    epsilon = 1e-5\n","    mape = np.mean(np.abs((actual - predictions) / np.maximum(np.abs(actual), epsilon))) * 100\n","    median_ae = median_absolute_error(actual, predictions)\n","    explained_variance = explained_variance_score(actual, predictions)\n","    mbd = np.mean(predictions - actual)\n","    try:\n","        msle = mean_squared_log_error(actual, predictions) \n","        # most ofter will be 0\n","    except ValueError as e:\n","        print(\"Error calculating MSLE:\", e)\n","        msle = None  # Handle cases where MSLE calculation fails\n","    \n","\n","    #If we choose to Convert to a Classification Problem, it would be also wise to have these metrics:\n","    threshold = np.mean(actual)  # Example threshold\n","    print(f'Threshold: {threshold}')\n","    accuracy = dynamic_regression_accuracy(actual, predictions, threshold) \n","    precision = calculate_precision_recall(actual, predictions, threshold)\n","    recall = calculate_recall(actual, predictions, threshold)\n","    conf_matrix = create_confusion_matrix(actual, predictions, threshold)\n","    \n","    \n","    print(f\"RMSE: {rmse}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"R²: {r2}\")\n","    print(f'MSE: {mse}')\n","    print(f'MAPE: {mape}%')\n","    print(f'Median Absolute Error: {median_ae}')\n","    print(f'Explained Variance Score: {explained_variance}')\n","    print(f'MSLE: {msle if msle is not None else \"Calculation failed due to negative or zero values\"}')\n","    print(f'Mean Bias Deviation: {mbd}')\n","    print(f'Accuracy: {accuracy}')\n","    print(f'Confusion Matrix:\\n{conf_matrix}')\n","    print(f'Precision: {precision}')\n","    print(f'Recall: {recall}')\n","    model_weights_path = f\"{name}_RNN_weights.h5\"\n","    model.save_weights(model_weights_path)\n","    \n","    RNN_models[name] = {\n","        'model': model,\n","        'actuals': actual,\n","        'predictions': predictions,\n","        'model_weights': model_weights_path,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'r2': r2,\n","        'mse': mse,\n","        'mape': mape,\n","        'median_ae': median_ae,\n","        'explained_variance': explained_variance,\n","        'msle': msle,\n","        'mbd': mbd,\n","        'accuracy': accuracy,\n","        'conf_matrix': conf_matrix,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","    points_in_24h = int((24 * 3600) / 7)\n","    # Plot results\n","    plt.figure(figsize=(20, 10))\n","    aligned_dates = df.index[split_point + window_size:split_point + window_size + len(actual)]\n","    aligned_dates_24h = aligned_dates[:points_in_24h]\n","    \n","    #store the results\n","    results_df = pd.DataFrame({\n","        'Date': aligned_dates,\n","        'Actual': actual.flatten(),\n","        'Predicted': predictions.flatten()\n","    })\n","\n","    results_df.to_csv(f\"RNN_{name}_results.csv\", index=False)\n","    print(f\"Results saved to RNN_{name}_results.csv\")\n","    #for  entire test period\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates, actual, label='Actual')\n","    plt.plot(aligned_dates, predictions, label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"RNN_House_{name}_full_results.jpeg\",format='jpeg', dpi=300 ) \n","    plt.show()\n","\n","    #for the first day\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates_24h, actual[:points_in_24h], label='Actual')\n","    plt.plot(aligned_dates_24h, predictions[:points_in_24h], label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name} - First 24 Hours')\n","    plt.legend()\n","    plt.grid(True)   \n","    plt.savefig(f\"RNN_House_{name}_24h_results.jpeg\", format='jpeg', dpi=300)  \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LSTM_models={}\n","tf.get_logger().setLevel('ERROR')\n","for name, df in houses.items():\n","    print(name)\n","    \n","    df = create_features(df)\n","    \n","    # Step 1: Proper Scaling\n","    aggregate = df['Aggregate'].values.reshape(-1, 1)\n","    additional_features = df[['Hour', 'Day_of_Week', 'Month', 'Lag_1', 'Lag_450', 'Lag_5400', 'Lag_10800']].values\n","\n","    # Scale after splitting to avoid leakage\n","    split_point = int(len(aggregate) * 0.80)\n","    \n","    scaler_aggregate = RobustScaler()\n","    train_aggregate = scaler_aggregate.fit_transform(aggregate[:split_point])\n","    test_aggregate = scaler_aggregate.transform(aggregate[split_point:])\n","\n","    scaler_additional = RobustScaler()\n","    train_additional_features = scaler_additional.fit_transform(additional_features[:split_point])\n","    test_additional_features = scaler_additional.transform(additional_features[split_point:])\n","\n","    # Step 5: Investigate Overfitting (Balanced Split)\n","    window_size = 24\n","    batch_size = 64\n","    train_generator = prepare_timeseries_generator(train_aggregate, train_additional_features, window_size=window_size, batch_size=batch_size)\n","    test_generator = prepare_timeseries_generator(test_aggregate, test_additional_features, window_size=window_size, batch_size=batch_size)\n","\n","    input_shape = (window_size, train_generator[0][0].shape[2])\n","\n","    model = create_lstm_model(input_shape=input_shape)\n","\n","    early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-3)\n","    print_cpu_usage(\"Initialization\")\n","    history = model.fit(train_generator, epochs=30, validation_data=test_generator, callbacks=[early_stopping, reduce_lr], batch_size=batch_size)\n","    print_cpu_usage(\"after training\")\n","    \n","    print_cpu_usage(\"before prediction\")\n","    predictions = model.predict(test_generator)\n","    actual = test_aggregate[window_size:]  #Align actuals &  predictions\n","\n","    actual = scaler_aggregate.inverse_transform(actual)\n","    predictions = scaler_aggregate.inverse_transform(predictions)\n","    print_cpu_usage(\"after prediction\")\n","\n","    #  metrics\n","    rmse = mean_squared_error(actual, predictions, squared = False)\n","    mae = mean_absolute_error(actual, predictions)\n","    r2 = r2_score(actual, predictions)\n","    mse = mean_squared_error(actual, predictions)\n","    \n","    # Extra classification metrics for curiosity \n","    epsilon = 1e-5\n","    mape = np.mean(np.abs((actual - predictions) / np.maximum(np.abs(actual), epsilon))) * 100\n","    median_ae = median_absolute_error(actual, predictions)\n","    explained_variance = explained_variance_score(actual, predictions)\n","    mbd = np.mean(predictions - actual)\n","    try:\n","        msle = mean_squared_log_error(actual, predictions) \n","        # most ofter will be 0\n","    except ValueError as e:\n","        print(\"Error calculating MSLE:\", e)\n","        msle = None  # Handle cases where MSLE calculation fails\n","    \n","\n","    #If we choose to Convert to a Classification Problem, it would be also wise to have these metrics:\n","    threshold = np.mean(actual)  # Example threshold\n","    print(f'Threshold: {threshold}')\n","    accuracy = dynamic_regression_accuracy(actual, predictions, threshold) \n","    precision = calculate_precision_recall(actual, predictions, threshold)\n","    recall = calculate_recall(actual, predictions, threshold)\n","    conf_matrix = create_confusion_matrix(actual, predictions, threshold)\n","    \n","    \n","    print(f\"RMSE: {rmse}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"R²: {r2}\")\n","    print(f'MSE: {mse}')\n","    print(f'MAPE: {mape}%')\n","    print(f'Median Absolute Error: {median_ae}')\n","    print(f'Explained Variance Score: {explained_variance}')\n","    print(f'MSLE: {msle if msle is not None else \"Calculation failed due to negative or zero values\"}')\n","    print(f'Mean Bias Deviation: {mbd}')\n","    print(f'Accuracy: {accuracy}')\n","    print(f'Confusion Matrix:\\n{conf_matrix}')\n","    print(f'Precision: {precision}')\n","    print(f'Recall: {recall}')\n","    model_weights_path = f\"{name}_LSTM_weights.h5\"\n","    model.save_weights(model_weights_path)\n","    \n","    LSTM_models[name] = {\n","        'model': model,\n","        'actuals': actual,\n","        'predictions': predictions,\n","        'model_weights': model_weights_path,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'r2': r2,\n","        'mse': mse,\n","        'mape': mape,\n","        'median_ae': median_ae,\n","        'explained_variance': explained_variance,\n","        'msle': msle,\n","        'mbd': mbd,\n","        'accuracy': accuracy,\n","        'conf_matrix': conf_matrix,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","    points_in_24h = int((24 * 3600) / 7)\n","    # Plot results\n","    plt.figure(figsize=(20, 10))\n","    aligned_dates = df.index[split_point + window_size:split_point + window_size + len(actual)]\n","    aligned_dates_24h = aligned_dates[:points_in_24h]\n","    \n","    #store the results\n","    results_df = pd.DataFrame({\n","        'Date': aligned_dates,\n","        'Actual': actual.flatten(),\n","        'Predicted': predictions.flatten()\n","    })\n","\n","    results_df.to_csv(f\"LSTM_{name}_results.csv\", index=False)\n","    print(f\"Results saved to LSTM_{name}_results.csv\")\n","    #for  entire test period\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates, actual, label='Actual')\n","    plt.plot(aligned_dates, predictions, label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"LSTM_House_{name}_full_results.jpeg\",format='jpeg', dpi=300 ) \n","    plt.show()\n","\n","    #for the first day\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates_24h, actual[:points_in_24h], label='Actual')\n","    plt.plot(aligned_dates_24h, predictions[:points_in_24h], label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name} - First 24 Hours')\n","    plt.legend()\n","    plt.grid(True)   \n","    plt.savefig(f\"LSTM_House_{name}_24h_results.jpeg\", format='jpeg', dpi=300)  \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["GRU_models={}\n","tf.get_logger().setLevel('ERROR')\n","for name, df in houses.items():\n","    print(name)\n","    \n","    df = create_features(df)\n","    \n","    # Step 1: Proper Scaling\n","    aggregate = df['Aggregate'].values.reshape(-1, 1)\n","    additional_features = df[['Hour', 'Day_of_Week', 'Month', 'Lag_1', 'Lag_450', 'Lag_5400', 'Lag_10800']].values\n","\n","    # Scale after splitting to avoid leakage\n","    split_point = int(len(aggregate) * 0.80)\n","    \n","    scaler_aggregate = RobustScaler()\n","    train_aggregate = scaler_aggregate.fit_transform(aggregate[:split_point])\n","    test_aggregate = scaler_aggregate.transform(aggregate[split_point:])\n","\n","    scaler_additional = RobustScaler()\n","    train_additional_features = scaler_additional.fit_transform(additional_features[:split_point])\n","    test_additional_features = scaler_additional.transform(additional_features[split_point:])\n","\n","    # Step 5: Investigate Overfitting (Balanced Split)\n","    window_size = 24\n","    batch_size = 64\n","    train_generator = prepare_timeseries_generator(train_aggregate, train_additional_features, window_size=window_size, batch_size=batch_size)\n","    test_generator = prepare_timeseries_generator(test_aggregate, test_additional_features, window_size=window_size, batch_size=batch_size)\n","\n","    input_shape = (window_size, train_generator[0][0].shape[2])\n","\n","    model = create_gru_model(input_shape=input_shape)\n","\n","    early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-3)\n","    print_cpu_usage(\"Initialization\")\n","    history = model.fit(train_generator, epochs=30, validation_data=test_generator, callbacks=[early_stopping, reduce_lr], batch_size=batch_size)\n","    print_cpu_usage(\"after training\")\n","    \n","    print_cpu_usage(\"before prediction\")\n","    predictions = model.predict(test_generator)\n","    actual = test_aggregate[window_size:]  #Align actuals &  predictions\n","\n","    actual = scaler_aggregate.inverse_transform(actual)\n","    predictions = scaler_aggregate.inverse_transform(predictions)\n","    print_cpu_usage(\"after prediction\")\n","\n","    #  metrics\n","    rmse = mean_squared_error(actual, predictions, squared = False)\n","    mae = mean_absolute_error(actual, predictions)\n","    r2 = r2_score(actual, predictions)\n","    mse = mean_squared_error(actual, predictions)\n","    \n","    # Extra classification metrics for curiosity \n","    epsilon = 1e-5\n","    mape = np.mean(np.abs((actual - predictions) / np.maximum(np.abs(actual), epsilon))) * 100\n","    median_ae = median_absolute_error(actual, predictions)\n","    explained_variance = explained_variance_score(actual, predictions)\n","    mbd = np.mean(predictions - actual)\n","    try:\n","        msle = mean_squared_log_error(actual, predictions) \n","        # most ofter will be 0\n","    except ValueError as e:\n","        print(\"Error calculating MSLE:\", e)\n","        msle = None  # Handle cases where MSLE calculation fails\n","    \n","\n","    #If we choose to Convert to a Classification Problem, it would be also wise to have these metrics:\n","    threshold = np.mean(actual)  # Example threshold\n","    print(f'Threshold: {threshold}')\n","    accuracy = dynamic_regression_accuracy(actual, predictions, threshold) \n","    precision = calculate_precision_recall(actual, predictions, threshold)\n","    recall = calculate_recall(actual, predictions, threshold)\n","    conf_matrix = create_confusion_matrix(actual, predictions, threshold)\n","    \n","    \n","    print(f\"RMSE: {rmse}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"R²: {r2}\")\n","    print(f'MSE: {mse}')\n","    print(f'MAPE: {mape}%')\n","    print(f'Median Absolute Error: {median_ae}')\n","    print(f'Explained Variance Score: {explained_variance}')\n","    print(f'MSLE: {msle if msle is not None else \"Calculation failed due to negative or zero values\"}')\n","    print(f'Mean Bias Deviation: {mbd}')\n","    print(f'Accuracy: {accuracy}')\n","    print(f'Confusion Matrix:\\n{conf_matrix}')\n","    print(f'Precision: {precision}')\n","    print(f'Recall: {recall}')\n","    model_weights_path = f\"{name}_GRU_weights.h5\"\n","    model.save_weights(model_weights_path)\n","    \n","    GRU_models[name] = {\n","        'model': model,\n","        'actuals': actual,\n","        'predictions': predictions,\n","        'model_weights': model_weights_path,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'r2': r2,\n","        'mse': mse,\n","        'mape': mape,\n","        'median_ae': median_ae,\n","        'explained_variance': explained_variance,\n","        'msle': msle,\n","        'mbd': mbd,\n","        'accuracy': accuracy,\n","        'conf_matrix': conf_matrix,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","    points_in_24h = int((24 * 3600) / 7)\n","    # Plot results\n","    plt.figure(figsize=(20, 10))\n","    aligned_dates = df.index[split_point + window_size:split_point + window_size + len(actual)]\n","    aligned_dates_24h = aligned_dates[:points_in_24h]\n","    \n","    #store the results\n","    results_df = pd.DataFrame({\n","        'Date': aligned_dates,\n","        'Actual': actual.flatten(),\n","        'Predicted': predictions.flatten()\n","    })\n","\n","    results_df.to_csv(f\"GRU_{name}_results.csv\", index=False)\n","    print(f\"Results saved to GRU_{name}_results.csv\")\n","    #for  entire test period\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates, actual, label='Actual')\n","    plt.plot(aligned_dates, predictions, label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"GRU_House_{name}_full_results.jpeg\",format='jpeg', dpi=300 ) \n","    plt.show()\n","\n","    #for the first day\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates_24h, actual[:points_in_24h], label='Actual')\n","    plt.plot(aligned_dates_24h, predictions[:points_in_24h], label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name} - First 24 Hours')\n","    plt.legend()\n","    plt.grid(True)   \n","    plt.savefig(f\"GRU_House_{name}_24h_results.jpeg\", format='jpeg', dpi=300)  \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BiLSTM_models={}\n","tf.get_logger().setLevel('ERROR')\n","for name, df in houses.items():\n","    print(name)\n","    \n","    df = create_features(df)\n","    \n","    # Step 1: Proper Scaling\n","    aggregate = df['Aggregate'].values.reshape(-1, 1)\n","    additional_features = df[['Hour', 'Day_of_Week', 'Month', 'Lag_1', 'Lag_450', 'Lag_5400', 'Lag_10800']].values\n","\n","    # Scale after splitting to avoid leakage\n","    split_point = int(len(aggregate) * 0.80)\n","    \n","    scaler_aggregate = RobustScaler()\n","    train_aggregate = scaler_aggregate.fit_transform(aggregate[:split_point])\n","    test_aggregate = scaler_aggregate.transform(aggregate[split_point:])\n","\n","    scaler_additional = RobustScaler()\n","    train_additional_features = scaler_additional.fit_transform(additional_features[:split_point])\n","    test_additional_features = scaler_additional.transform(additional_features[split_point:])\n","\n","    # Step 5: Investigate Overfitting (Balanced Split)\n","    window_size = 24\n","    batch_size = 64\n","    train_generator = prepare_timeseries_generator(train_aggregate, train_additional_features, window_size=window_size, batch_size=batch_size)\n","    test_generator = prepare_timeseries_generator(test_aggregate, test_additional_features, window_size=window_size, batch_size=batch_size)\n","\n","    input_shape = (window_size, train_generator[0][0].shape[2])\n","\n","    model = create_bilstm_model(input_shape=input_shape)\n","\n","    early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-3)\n","    print_cpu_usage(\"Initialization\")\n","    history = model.fit(train_generator, epochs=30, validation_data=test_generator, callbacks=[early_stopping, reduce_lr], batch_size=batch_size)\n","    print_cpu_usage(\"after training\")\n","    \n","    print_cpu_usage(\"before prediction\")\n","    predictions = model.predict(test_generator)\n","    actual = test_aggregate[window_size:]  #Align actuals &  predictions\n","\n","    actual = scaler_aggregate.inverse_transform(actual)\n","    predictions = scaler_aggregate.inverse_transform(predictions)\n","    print_cpu_usage(\"after prediction\")\n","\n","    #  metrics\n","    rmse = mean_squared_error(actual, predictions, squared = False)\n","    mae = mean_absolute_error(actual, predictions)\n","    r2 = r2_score(actual, predictions)\n","    mse = mean_squared_error(actual, predictions)\n","    \n","    # Extra classification metrics for curiosity \n","    epsilon = 1e-5\n","    mape = np.mean(np.abs((actual - predictions) / np.maximum(np.abs(actual), epsilon))) * 100\n","    median_ae = median_absolute_error(actual, predictions)\n","    explained_variance = explained_variance_score(actual, predictions)\n","    mbd = np.mean(predictions - actual)\n","    try:\n","        msle = mean_squared_log_error(actual, predictions) \n","        # most ofter will be 0\n","    except ValueError as e:\n","        print(\"Error calculating MSLE:\", e)\n","        msle = None  # Handle cases where MSLE calculation fails\n","    \n","\n","    #If we choose to Convert to a Classification Problem, it would be also wise to have these metrics:\n","    threshold = np.mean(actual)  # Example threshold\n","    print(f'Threshold: {threshold}')\n","    accuracy = dynamic_regression_accuracy(actual, predictions, threshold) \n","    precision = calculate_precision_recall(actual, predictions, threshold)\n","    recall = calculate_recall(actual, predictions, threshold)\n","    conf_matrix = create_confusion_matrix(actual, predictions, threshold)\n","    \n","    \n","    print(f\"RMSE: {rmse}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"R²: {r2}\")\n","    print(f'MSE: {mse}')\n","    print(f'MAPE: {mape}%')\n","    print(f'Median Absolute Error: {median_ae}')\n","    print(f'Explained Variance Score: {explained_variance}')\n","    print(f'MSLE: {msle if msle is not None else \"Calculation failed due to negative or zero values\"}')\n","    print(f'Mean Bias Deviation: {mbd}')\n","    print(f'Accuracy: {accuracy}')\n","    print(f'Confusion Matrix:\\n{conf_matrix}')\n","    print(f'Precision: {precision}')\n","    print(f'Recall: {recall}')\n","    model_weights_path = f\"{name}_BiLSTM_weights.h5\"\n","    model.save_weights(model_weights_path)\n","    \n","    BiLSTM_models[name] = {\n","        'model': model,\n","        'actuals': actual,\n","        'predictions': predictions,\n","        'model_weights': model_weights_path,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'r2': r2,\n","        'mse': mse,\n","        'mape': mape,\n","        'median_ae': median_ae,\n","        'explained_variance': explained_variance,\n","        'msle': msle,\n","        'mbd': mbd,\n","        'accuracy': accuracy,\n","        'conf_matrix': conf_matrix,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","    points_in_24h = int((24 * 3600) / 7)\n","    # Plot results\n","    plt.figure(figsize=(20, 10))\n","    aligned_dates = df.index[split_point + window_size:split_point + window_size + len(actual)]\n","    aligned_dates_24h = aligned_dates[:points_in_24h]\n","    \n","    #store the results\n","    results_df = pd.DataFrame({\n","        'Date': aligned_dates,\n","        'Actual': actual.flatten(),\n","        'Predicted': predictions.flatten()\n","    })\n","\n","    results_df.to_csv(f\"BiLSTM_{name}_results.csv\", index=False)\n","    print(f\"Results saved to BiLSTM_{name}_results.csv\")\n","    #for  entire test period\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates, actual, label='Actual')\n","    plt.plot(aligned_dates, predictions, label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"BiLSTM{name}_full_results.jpeg\",format='jpeg', dpi=300 ) \n","    plt.show()\n","\n","    #for the first day\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates_24h, actual[:points_in_24h], label='Actual')\n","    plt.plot(aligned_dates_24h, predictions[:points_in_24h], label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name} - First 24 Hours')\n","    plt.legend()\n","    plt.grid(True)   \n","    plt.savefig(f\"BiLSTM_{name}_24h_results.jpeg\", format='jpeg', dpi=300)  \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Transformer_models={}\n","tf.get_logger().setLevel('ERROR')\n","for name, df in houses.items():\n","    print(name)\n","    \n","    df = create_features(df)\n","    \n","    # Step 1: Proper Scaling\n","    aggregate = df['Aggregate'].values.reshape(-1, 1)\n","    additional_features = df[['Hour', 'Day_of_Week', 'Month', 'Lag_1', 'Lag_450', 'Lag_5400', 'Lag_10800']].values\n","\n","    # Scale after splitting to avoid leakage\n","    split_point = int(len(aggregate) * 0.80)\n","    \n","    scaler_aggregate = RobustScaler()\n","    train_aggregate = scaler_aggregate.fit_transform(aggregate[:split_point])\n","    test_aggregate = scaler_aggregate.transform(aggregate[split_point:])\n","\n","    scaler_additional = RobustScaler()\n","    train_additional_features = scaler_additional.fit_transform(additional_features[:split_point])\n","    test_additional_features = scaler_additional.transform(additional_features[split_point:])\n","\n","    # Step 5: Investigate Overfitting (Balanced Split)\n","    window_size = 24\n","    batch_size = 64\n","    train_generator = prepare_timeseries_generator(train_aggregate, train_additional_features, window_size=window_size, batch_size=batch_size)\n","    test_generator = prepare_timeseries_generator(test_aggregate, test_additional_features, window_size=window_size, batch_size=batch_size)\n","\n","    input_shape = (window_size, train_generator[0][0].shape[2])\n","\n","    model = cnn_lstm_attention_transformer_model(input_shape=input_shape, dropout=0.2, weight_decay=1e-7)\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n","    print_cpu_usage(\"Initialization\")\n","    history = model.fit(train_generator, epochs=30, validation_data=test_generator, callbacks=[early_stopping, reduce_lr], batch_size=batch_size)\n","    print_cpu_usage(\"after training\")\n","    \n","    print_cpu_usage(\"before prediction\")\n","    predictions = model.predict(test_generator)\n","    actual = test_aggregate[window_size:]  #Align actuals &  predictions\n","\n","    actual = scaler_aggregate.inverse_transform(actual)\n","    predictions = scaler_aggregate.inverse_transform(predictions)\n","    print_cpu_usage(\"after prediction\")\n","\n","    #  metrics\n","    rmse = mean_squared_error(actual, predictions, squared = False)\n","    mae = mean_absolute_error(actual, predictions)\n","    r2 = r2_score(actual, predictions)\n","    mse = mean_squared_error(actual, predictions)\n","    \n","    # Extra classification metrics for curiosity \n","    epsilon = 1e-5\n","    mape = np.mean(np.abs((actual - predictions) / np.maximum(np.abs(actual), epsilon))) * 100\n","    median_ae = median_absolute_error(actual, predictions)\n","    explained_variance = explained_variance_score(actual, predictions)\n","    mbd = np.mean(predictions - actual)\n","    try:\n","        msle = mean_squared_log_error(actual, predictions) \n","        # most ofter will be 0\n","    except ValueError as e:\n","        print(\"Error calculating MSLE:\", e)\n","        msle = None  # Handle cases where MSLE calculation fails\n","    \n","\n","    #If we choose to Convert to a Classification Problem, it would be also wise to have these metrics:\n","    threshold = np.mean(actual)  # Example threshold\n","    print(f'Threshold: {threshold}')\n","    accuracy = dynamic_regression_accuracy(actual, predictions, threshold) \n","    precision = calculate_precision_recall(actual, predictions, threshold)\n","    recall = calculate_recall(actual, predictions, threshold)\n","    conf_matrix = create_confusion_matrix(actual, predictions, threshold)\n","    \n","    \n","    print(f\"RMSE: {rmse}\")\n","    print(f\"MAE: {mae}\")\n","    print(f\"R²: {r2}\")\n","    print(f'MSE: {mse}')\n","    print(f'MAPE: {mape}%')\n","    print(f'Median Absolute Error: {median_ae}')\n","    print(f'Explained Variance Score: {explained_variance}')\n","    print(f'MSLE: {msle if msle is not None else \"Calculation failed due to negative or zero values\"}')\n","    print(f'Mean Bias Deviation: {mbd}')\n","    print(f'Accuracy: {accuracy}')\n","    print(f'Confusion Matrix:\\n{conf_matrix}')\n","    print(f'Precision: {precision}')\n","    print(f'Recall: {recall}')\n","    model_weights_path = f\"{name}_Transformers_weights.h5\"\n","    model.save_weights(model_weights_path)\n","    \n","    Transformer_models[name] = {\n","        'model': model,\n","        'actuals': actual,\n","        'predictions': predictions,\n","        'model_weights': model_weights_path,\n","        'rmse': rmse,\n","        'mae': mae,\n","        'r2': r2,\n","        'mse': mse,\n","        'mape': mape,\n","        'median_ae': median_ae,\n","        'explained_variance': explained_variance,\n","        'msle': msle,\n","        'mbd': mbd,\n","        'accuracy': accuracy,\n","        'conf_matrix': conf_matrix,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","    points_in_24h = int((24 * 3600) / 7)\n","    # Plot results\n","    plt.figure(figsize=(20, 10))\n","    aligned_dates = df.index[split_point + window_size:split_point + window_size + len(actual)]\n","    aligned_dates_24h = aligned_dates[:points_in_24h]\n","    \n","    #store the results\n","    results_df = pd.DataFrame({\n","        'Date': aligned_dates,\n","        'Actual': actual.flatten(),\n","        'Predicted': predictions.flatten()\n","    })\n","\n","    results_df.to_csv(f\"Hybrid_{name}_results.csv\", index=False)\n","    print(f\"Results saved to Hybrid_{name}_results.csv\")\n","    #for  entire test period\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates, actual, label='Actual')\n","    plt.plot(aligned_dates, predictions, label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig(f\"Hybrid_House_{name}_full_results.jpeg\",format='jpeg', dpi=300 ) \n","    plt.show()\n","\n","    #for the first day\n","    plt.figure(figsize=(20, 10))\n","    plt.plot(aligned_dates_24h, actual[:points_in_24h], label='Actual')\n","    plt.plot(aligned_dates_24h, predictions[:points_in_24h], label='Predicted', linestyle='--')\n","    plt.xlabel('Time')\n","    plt.ylabel('Energy Consumption')\n","    plt.title(f'Actual vs Predicted for {name} - First 24 Hours')\n","    plt.legend()\n","    plt.grid(True)   \n","    plt.savefig(f\"Hybrid_House_{name}_24h_results.jpeg\", format='jpeg', dpi=300)  \n","    plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
